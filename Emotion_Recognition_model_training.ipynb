{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcedac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report,ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50f4ba98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize image data generator with rescaling\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "validation_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Preprocess all test images\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Preprocess all train images\n",
    "validation_generator = validation_data_gen.flow_from_directory(\n",
    "        'data/test',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3cf3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model structure\n",
    "emotion_model = Sequential()\n",
    "\n",
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "emotion_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48f75c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('models/emotion_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "emotion_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "emotion_model.load_weights(\"models/emotion_model.h5\")\n",
    "emotion_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b77ad8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "448/448 [==============================] - 481s 1s/step - loss: 0.5090 - accuracy: 0.8152 - val_loss: 1.1223 - val_accuracy: 0.6321\n",
      "Epoch 2/20\n",
      "448/448 [==============================] - 164s 367ms/step - loss: 0.4932 - accuracy: 0.8246 - val_loss: 1.1491 - val_accuracy: 0.6260\n",
      "Epoch 3/20\n",
      "448/448 [==============================] - 168s 374ms/step - loss: 0.4720 - accuracy: 0.8296 - val_loss: 1.1538 - val_accuracy: 0.6247\n",
      "Epoch 4/20\n",
      "448/448 [==============================] - 172s 384ms/step - loss: 0.4573 - accuracy: 0.8335 - val_loss: 1.1481 - val_accuracy: 0.6275\n",
      "Epoch 5/20\n",
      "448/448 [==============================] - 173s 386ms/step - loss: 0.4408 - accuracy: 0.8401 - val_loss: 1.1779 - val_accuracy: 0.6290\n",
      "Epoch 6/20\n",
      "448/448 [==============================] - 169s 377ms/step - loss: 0.4318 - accuracy: 0.8430 - val_loss: 1.1649 - val_accuracy: 0.6350\n",
      "Epoch 7/20\n",
      "448/448 [==============================] - 175s 391ms/step - loss: 0.4105 - accuracy: 0.8512 - val_loss: 1.1894 - val_accuracy: 0.6286\n",
      "Epoch 8/20\n",
      "448/448 [==============================] - 164s 365ms/step - loss: 0.4008 - accuracy: 0.8554 - val_loss: 1.1863 - val_accuracy: 0.6293\n",
      "Epoch 9/20\n",
      "448/448 [==============================] - 164s 366ms/step - loss: 0.3887 - accuracy: 0.8586 - val_loss: 1.2142 - val_accuracy: 0.6324\n",
      "Epoch 10/20\n",
      "448/448 [==============================] - 163s 365ms/step - loss: 0.3782 - accuracy: 0.8643 - val_loss: 1.2177 - val_accuracy: 0.6306\n",
      "Epoch 11/20\n",
      "448/448 [==============================] - 163s 365ms/step - loss: 0.3686 - accuracy: 0.8684 - val_loss: 1.2248 - val_accuracy: 0.6300\n",
      "Epoch 12/20\n",
      "448/448 [==============================] - 164s 366ms/step - loss: 0.3576 - accuracy: 0.8715 - val_loss: 1.2210 - val_accuracy: 0.6272\n",
      "Epoch 13/20\n",
      "448/448 [==============================] - 163s 364ms/step - loss: 0.3436 - accuracy: 0.8759 - val_loss: 1.2425 - val_accuracy: 0.6289\n",
      "Epoch 14/20\n",
      "448/448 [==============================] - 163s 364ms/step - loss: 0.3330 - accuracy: 0.8817 - val_loss: 1.2445 - val_accuracy: 0.6303\n",
      "Epoch 15/20\n",
      "448/448 [==============================] - 163s 364ms/step - loss: 0.3272 - accuracy: 0.8812 - val_loss: 1.2580 - val_accuracy: 0.6309\n",
      "Epoch 16/20\n",
      "448/448 [==============================] - 163s 364ms/step - loss: 0.3209 - accuracy: 0.8843 - val_loss: 1.2543 - val_accuracy: 0.6258\n",
      "Epoch 17/20\n",
      "448/448 [==============================] - 163s 364ms/step - loss: 0.3053 - accuracy: 0.8921 - val_loss: 1.2702 - val_accuracy: 0.6264\n",
      "Epoch 18/20\n",
      "448/448 [==============================] - 164s 365ms/step - loss: 0.3010 - accuracy: 0.8910 - val_loss: 1.2601 - val_accuracy: 0.6292\n",
      "Epoch 19/20\n",
      "448/448 [==============================] - 163s 364ms/step - loss: 0.2889 - accuracy: 0.8967 - val_loss: 1.2953 - val_accuracy: 0.6286\n",
      "Epoch 20/20\n",
      "448/448 [==============================] - 163s 364ms/step - loss: 0.2872 - accuracy: 0.8973 - val_loss: 1.2867 - val_accuracy: 0.6285\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network/model\n",
    "emotion_model_info = emotion_model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=28709 // 64,\n",
    "        epochs=20,        validation_data=validation_generator,\n",
    "        validation_steps=7178 // 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ec2d336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 6s 54ms/step - loss: 1.2877 - accuracy: 0.6286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.287705421447754, 0.6285873651504517]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16a15825",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = emotion_model.to_json()\n",
    "with open(\"models/emotion_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# save trained model weight in .h5 file\n",
    "emotion_model.save_weights('models/emotion_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
